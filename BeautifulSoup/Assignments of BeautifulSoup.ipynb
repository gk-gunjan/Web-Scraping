{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the data of first 3 movies\n",
    "Send Feedback\n",
    "From this link,\n",
    "Find and print the name and genre of the first 3 titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Infinity War ;Action, Adventure, Sci-Fi\n",
      "Black Panther ;Action, Adventure, Sci-Fi\n",
      "Deadpool 2 ;Action, Adventure, Comedy\n"
     ]
    }
   ],
   "source": [
    "base_url='https://www.imdb.com/search/title/?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt'\n",
    "response=requests.get(base_url)\n",
    "data=soup(response.text,'html.parser')\n",
    "d1=data.find_all(class_='lister-item-header')\n",
    "d2=data.find_all(class_='genre')\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(d1[i].a.string,\";\",end='')\n",
    "    d2[i] = d2[i].string.strip()\n",
    "    d2[i] = d2[i].split(\",\")\n",
    "    for p in range(len(d2[i])):\n",
    "        if p==len(d2[i])-1:\n",
    "            print(d2[i][p])\n",
    "        else:\n",
    "            print(d2[i][p],end=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### titles with most votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception\n",
      "Game of Thrones\n",
      "The Dark Knight Rises\n",
      "The Wolf of Wall Street\n",
      "Interstellar\n"
     ]
    }
   ],
   "source": [
    "for i in range(2010,2015):\n",
    "    \n",
    "    base_url='https://www.imdb.com/search/title?release_date='+str(i)+'-01-01,'+str(i)+'-12-31&sort=num_votes,desc&page=1&ref_=adv_nxt'\n",
    "    response=requests.get(base_url)\n",
    "    data=soup(response.text,'html.parser')\n",
    "    title=data.find(class_='lister-item-header')\n",
    "    name=title.find('a').string.strip()\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title with maximum duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-481c92740003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lister-item-header'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'runtime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/dt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmaxi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    200\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import re\n",
    "base_url='https://www.imdb.com/search/title?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt'\n",
    "response=requests.get(base_url)\n",
    "data=soup(response.text,'html.parser')\n",
    "title=data.find_all(class_='lister-item-header')\n",
    "duration=data.find_all(class_='runtime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,re\n",
    "from bs4 import BeautifulSoup\n",
    "basic='https://www.imdb.com'\n",
    "basic_url='https://www.imdb.com/search/title/?release_date=2018'\n",
    "ext_url='&sort=num_votes,desc&page=1&ref_=adv_nxt'\n",
    "\n",
    "curr_url=basic_url+ext_url\n",
    "li=[]\n",
    "li2=[]\n",
    "for i in range(5):\n",
    "    \n",
    "    response=requests.get(curr_url)\n",
    "    data=BeautifulSoup(response.text,'html.parser')\n",
    "    d=data.find_all(class_='desc')\n",
    "    #curr_url=basic+(d[-1].a['href'])\n",
    "    if i==0:\n",
    "        curr_url=basic+d[1].find_all('a')[0]['href']\n",
    "    else:\n",
    "        curr_url=basic+d[1].find_all('a')[1]['href']\n",
    "    x=data.find_all(class_='lister-item-header')\n",
    "    for j in x:\n",
    "        li.append(j.a.contents[-1].strip())\n",
    "    y=data.find_all(class_='runtime')\n",
    "    for m in y:\n",
    "        time=re.search('[\\d,]+',m.string).group()\n",
    "\n",
    "        if ',' in time:\n",
    "            l=[time.split(',')]\n",
    "\n",
    "            for ele in l:\n",
    "                s=\"\".join(ele)\n",
    "                li2.append(int(s))\n",
    "        else:\n",
    "            li2.append(int(time))\n",
    "print(li[li2.index(max(li2))],max(li2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quotes with tag humor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "“A day without sunshine is like, you know, night.”\n",
      "“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”\n",
      "“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”\n",
      "“All you need is love. But a little chocolate now and then doesn't hurt.”\n",
      "“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\n",
      "“Some people never go crazy. What truly horrible lives they must lead.”\n",
      "“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”\n",
      "“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”\n",
      "“The reason I talk to myself is because I’m the only one whose answers I accept.”\n",
      "“I am free of all prejudice. I hate everyone equally. ”\n",
      "“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "for i in range(1,3):\n",
    "    base_url='http://quotes.toscrape.com/tag/humor/page/'+str(i)+'/'\n",
    "    response=requests.get(base_url)\n",
    "    data=soup(response.text,'html.parser')\n",
    "    quote=data.find_all(class_='quote')\n",
    "    for i in quote:\n",
    "        print(i.span.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print all authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein\n",
      "Alexandre Dumas fils\n",
      "Alfred Tennyson\n",
      "Allen Saunders\n",
      "André Gide\n",
      "Ayn Rand\n",
      "Bob Marley\n",
      "C.S. Lewis\n",
      "Charles Bukowski\n",
      "Charles M. Schulz\n",
      "Douglas Adams\n",
      "Dr. Seuss\n",
      "E.E. Cummings\n",
      "Eleanor Roosevelt\n",
      "Elie Wiesel\n",
      "Ernest Hemingway\n",
      "Friedrich Nietzsche\n",
      "Garrison Keillor\n",
      "George Bernard Shaw\n",
      "George Carlin\n",
      "George Eliot\n",
      "George R.R. Martin\n",
      "Harper Lee\n",
      "Haruki Murakami\n",
      "Helen Keller\n",
      "J.D. Salinger\n",
      "J.K. Rowling\n",
      "J.M. Barrie\n",
      "J.R.R. Tolkien\n",
      "James Baldwin\n",
      "Jane Austen\n",
      "Jim Henson\n",
      "Jimi Hendrix\n",
      "John Lennon\n",
      "Jorge Luis Borges\n",
      "Khaled Hosseini\n",
      "Madeleine L'Engle\n",
      "Marilyn Monroe\n",
      "Mark Twain\n",
      "Martin Luther King Jr.\n",
      "Mother Teresa\n",
      "Pablo Neruda\n",
      "Ralph Waldo Emerson\n",
      "Stephenie Meyer\n",
      "Steve Martin\n",
      "Suzanne Collins\n",
      "Terry Pratchett\n",
      "Thomas A. Edison\n",
      "W.C. Fields\n",
      "William Nicholson\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "lis=[]\n",
    "for i in range(1,11):\n",
    "    base_url='http://quotes.toscrape.com/page/'+str(i)+'/'\n",
    "    response=requests.get(base_url)\n",
    "    data=soup(response.text,'html.parser')\n",
    "    find=data.find_all(class_='author')\n",
    "    for i in find:\n",
    "        lis.append(i.string)\n",
    "d={}\n",
    "lis.sort()\n",
    "for i in lis:\n",
    "    if i in d:\n",
    "        d[i]+=1\n",
    "    else:\n",
    "        d[i]=1\n",
    "for i in d:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
